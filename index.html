<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Aaron Hao Tan</title>
  
  <meta name="author" content="Aaron Hao Tan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Aaron Hao Tan</name>
              </p>

              <p>
                I am a Ph.D. candidate, advised by Dr. <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>, at the <a href="https://robotics.utoronto.ca/">University of Toronto Robotics Institute</a>, where I work on deep reinforcement learning for multi-robot coordination in unknown, unstructured, and communication-limited environments.
              </p>

              <p>
                Previously, I worked on a multi-wheeled mobile robotic system with Dr. <a href="https://scholar.google.ca/citations?user=XOI7ib4AAAAJ&hl=en">Moustafa El-Gindy</a> and vision-based mobile manipulator control with Dr. <a href="https://scholar.google.com/citations?user=GcttJ-oAAAAJ&hl=en">Haoxiang Lang</a>.
                During my internship at <a href="https://www.gm.ca/en/home.html">General Motors</a>, I worked on rider sweat prediction for the <a href="https://www.youtube.com/watch?v=WCD9Q_Y4WIA&ab_channel=PedelecsundE-Bikes">ARIV E-Bike</a> project.
              </p>

              <p>
                Outside of my primary research, I collaborate with Dr. <a href="https://torontoeye.ca/dr-edward-margolin/">Edward Margolin</a> and Dr. <a href="https://www.prismeyeinstitute.com/about/our-doctors/dr-matt-schlenker/">Matthew Schlenker</a> to develop AI-based tools to enhance cataract surgery and disease detection.
                I am also a machine learning and robotics consultant at <a href="https://smartarm.ca/">SmartARM</a>.
              </p>

              <p style="text-align:center">
                <a href="mailto:aaronhao.tan@utoronto.ca">Email</a> &nbsp/&nbsp
                <a href="files/resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=VSW55LkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/aaronhaotan">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/aarontan-git">Github</a> &nbsp/&nbsp <br>
                <a href="https://utoronto-my.sharepoint.com/:f:/g/personal/aaronhao_tan_utoronto_ca/EsclIvvXcN5PseaKFZUfKu8BTeAabLBW7LHbE4VhnVA69A?e=DnyBb2">Shot on iPhone (under development)</a>

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/aaronhaotan.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/aaronhaotan.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I have worked on novel hardware designs for mobile robots, as well as autonomous navigation and multi-robot cooperation to address the challenges of rough terrain, cluttered and communication-limited environments.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfsuper_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/madenet_thumb.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
              </div>
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://arxiv.org/abs/2110.02181">
                <papertitle>Deep Reinforcement Learning for Decentralized Multi-Robot Exploration with Macro Actions</papertitle>
              </a>
              <br>
              <strong>Aaron Hao Tan</strong>,
              <a href="https://www.linkedin.com/in/federico-pizarro-bejarano/?originalSubdomain=ca">Federico Pizzaro Bejarano</a>, 
              <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>
              <br>
              <em>Submitted</em>, 2021
              <br>
							<a href="https://arxiv.org/abs/2110.02181">arXiv</a>
              /
							<a href="files/made-net.pdf">Poster</a>
              <p></p>
              <p>The first Macro Action Decentralized Exploration Network (MADE-Net) using multi-agent deep reinforcement learning to address the challenges of communication dropouts during multi-robot exploration in unseen, unstructured, and cluttered environments.</p>
            </td>
          </tr>
					
          <tr></tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='sim2real_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/sim2real.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/9468918">
                <papertitle>A Sim-to-Real Pipeline for Deep Reinforcement Learning for Autonomous Robot Navigation in Cluttered Rough Terrain</papertitle>
              </a>
              <br>
              <a href="https://rhklite.github.io/dist/index.html#publications">Han Hu</a>,
              <a href="https://www.linkedin.com/in/kczhang/?originalSubdomain=ca">Kaicheng Zhang</a>,

              <strong>Aaron Hao Tan</strong>,
              <a href="https://www.linkedin.com/in/m-ruan/?originalSubdomain=ca">Michael Ruan</a>,
              <a href="https://www.chrisagia.com/">Christopher Agia</a>,
              <a href="https://scholar.google.ca/citations?user=1pCgjH0AAAAJ&hl=en">Goldie Nejat</a>
              <br>
							<em>IEEE Robotics and Automation Letters + IROS</em>, 2021 &nbsp
              <br>
              <a href="https://ieeexplore.ieee.org/abstract/document/9468918">Paper</a>
              /
              <a href="https://www.youtube.com/watch?v=GuE7cfknckg&ab_channel=AutonomousSystemsandBiomechatronicsLab%28UniversityofToronto%29">Talk</a>
              /
              <a href="https://www.youtube.com/watch?v=dtYlNWvK-7k&ab_channel=AutonomousSystemsandBiomechatronicsLab%28UniversityofToronto%29">Video</a>
              <p></p>
              <p>The development of a novel sim-to-real pipeline for a mobile robot to effectively learn how to navigate real-world 3D rough terrain environments.</p>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='eight_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/8x8_loop.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <!-- <img src='images/8x8_static.png' width="160"> -->
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://www.cambridge.org/core/journals/robotica/article/design-and-development-of-a-novel-autonomous-scaled-multiwheeled-vehicle/1029552C3A421608255F87C045E52FFA">
                  <papertitle>Design and development of a novel autonomous scaled multiwheeled vehicle</papertitle>
                </a>
                <br>
                <strong>Aaron Hao Tan</strong>,
                Michael Peiris,
                <a href="https://scholar.google.ca/citations?user=XOI7ib4AAAAJ&hl=en">Moustafa El-Gindy</a>,
                <a href="https://scholar.google.com/citations?user=GcttJ-oAAAAJ&hl=en">Haoxiang Lang</a> <br>
                <em>Robotica</em>, 2021 &nbsp
                <br>
                <a href="https://www.cambridge.org/core/journals/robotica/article/design-and-development-of-a-novel-autonomous-scaled-multiwheeled-vehicle/1029552C3A421608255F87C045E52FFA">Paper</a>
                /
                <a href="files/8x8 Presentation.pdf">Slides</a>
                /
                <a href="https://www.youtube.com/watch?v=42oM5fr4juA&ab_channel=AaronTan">Video</a>
                <p></p>
                <p>A 1:6 scale, multi-wheeled mobile robotic platform with independent suspension, steering and actuation for off-terrain operations.</p>
            </td>
          </tr>

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Robotics Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

        <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
              <source src="images/refnerf.mp4" type="video/mp4">
              Your browser does not support the video tag.
              </video></div>
              <img src='images/jeeves.png' width="160">
            </div>
            <script type="text/javascript">
              function refnerf_start() {
                document.getElementById('refnerf_image').style.opacity = "1";
              }

              function refnerf_stop() {
                document.getElementById('refnerf_image').style.opacity = "0";
              }
              refnerf_stop()
            </script>
          </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Jeeves, the Ethically Designed Interface</papertitle>
              <br>
              <strong>Aaron Hao Tan</strong>,
              <a href="https://www.linkedin.com/in/angus-fung-a9751b87/?originalSubdomain=ca">Angus Fung</a>,
              <a href="https://mphamhung.github.io/">Michael Pham-Hung</a>,
              <a href="https://twitter.com/CristinaGetson?s=20&t=Bx9xTA9JIkqdG5aEvfR-jg">Cristina Getson</a> <br>
              <em><a href="https://sites.google.com/view/ro-man-2021-r2d2/competition-results?authuser=0">RO-MAN: Roboethics Competition</a></em>, 2021 &nbsp
              <br>
              <a href="https://drive.google.com/file/d/1fCun8B-wVhRI5f0-AeNcamaFSntH5N1u/view">Talk</a>
              <p></p>
              <p>A competition designed to answer: how can robots respond and interact in an ethical manner when delivery objects within a domestic setting?</p>
            </td>
          </tr>

          <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/trav_est_480.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
              </div>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Mobile Robot Traversability Estimation with CNN</papertitle>
                <br>
                <strong>Aaron Hao Tan</strong>, 2019 &nbsp
                <br>
                <a href="https://www.youtube.com/watch?v=DjA-FNGtTs4&ab_channel=AaronTan">Video</a>
                <p></p>
                <p>Reproduced results from <a href="https://ieeexplore.ieee.org/abstract/document/8280544">Learning Ground Traversability from Simulations</a> on a custom environment.</p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vs.mov" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
              </div>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Image and Position based Visual Servoing</papertitle>
                <br>
                <strong>Aaron Hao Tan</strong>, 2018
                <br>
                <a href="https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings-abstract/IDETC-CIE2018/V05AT07A078/275147">Image Based</a>
                /
                <a href="https://ieeexplore.ieee.org/abstract/document/8439978">Position Based</a>
                /
                <a href="https://www.youtube.com/watch?v=dzXyfbeat6g&ab_channel=AaronTan">UR5</a>
                /
                <a href="https://www.youtube.com/watch?v=x6bPpbCUvog&ab_channel=AaronTan">Docking</a>
                <p></p>
                <p>Implemented image and position-based visual servoing on a Clearpath Husky and UR5 Manipulator.</p>
              </td>
            </tr>

            <!-- <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()"> -->
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='refnerf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/navigation.mov" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <!-- <img src='images/refnerf.jpg' width="160"> -->
                </div>

              </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Autonomous Navigation and Mapping</papertitle>
                  <br>
                  <strong>Aaron Hao Tan</strong>, 2018
                  <br>
                  <a href="https://www.youtube.com/watch?v=fM0ft-QHnnk&ab_channel=AaronTan">Indoor</a>/
                  <a href="https://youtu.be/wglpGi9582k">Outdoor</a>

                  <p></p>
                  <p>Implemented open source mapping, localization and navigation algorithms with Clearpath Husky.</p>
                </td>
              </tr>
  



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Machine Learning Projects</heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">

              <img src='images/hvf_input.png' width="160">
            </div>
          </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>A Deep Learning Model to Identify Homonymous Defects on Automated Perimetry</papertitle>
              <br>
              <strong>Aaron Hao Tan</strong>,
              <a href="https://www.linkedin.com/in/austin-pereira-953199b9/">Laura Donaldson</a>,
              <a href="https://www.linkedin.com/in/austin-pereira-953199b9/">Luqmaan Moolla</a>,
              <a href="https://www.prismeyeinstitute.com/about/our-doctors/dr-matt-schlenker/">Edward Margolin</a>
              <br>
              <em><a href="https://www.nanosweb.org/i4a/pages/index.cfm?pageid=4229">NANOS</a></em>, 2022 &nbsp
              <br>
              <a href="files/NANOS2022AI.pdf">Slide</a>
              <p></p>
              <p>The first application of deep learning to the classification of homonymous defects on automated perimetry.</p>
            </td>
          </tr>



        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <div class="one">
              <img src='images/iol.png' width="160">
            </div>
          </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>A Deep Learning Model to Predict Postoperative Refraction in Cataract Surgery</papertitle>
              <br>
              <strong>Aaron Hao Tan</strong>,
              <a href="https://www.linkedin.com/in/austin-pereira-953199b9/">Luqmaan Moolla</a>,
              <a href="https://www.linkedin.com/in/austin-pereira-953199b9/">Austin Pereira</a>,
              <a href="https://www.prismeyeinstitute.com/about/our-doctors/dr-matt-schlenker/">Matthew Schlenker</a>,
              2021
              <br>
              <a href="files/IOL-AI-Manuscript-Figures.pdf">Report</a> /
              <a href="files/Toronto-AI-IOL-Model-Presentation-final.pdf">Slide</a>
              <p></p>
              <p>Our model demonstrated a higher accuracy and precision than both a modern IOL power formula (Barrett Universal II) and two classical ML approaches in predicting postoperative refraction in our data set of 2490 eyes. </p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/mdp.png' width="160">
              </div>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Dynamic and Distributed Decision Making</papertitle>
                <br>
                <strong>Aaron Hao Tan</strong>, 2020 &nbsp
                <br>
                <a href="https://github.com/aarontan-git/MDP">MDP</a>
                /
                <a href="https://github.com/aarontan-git/RL_algorithms">RL</a>
                /
                <a href="https://github.com/aarontan-git/multi_agent_learning">MARL</a>
                <p></p>
                <p>Implemented value/policy iteration, Monte Carlo, QLearning, SARSA, TD-Lambda, Shapley's Value Iteration and Minimax QLearning</p>
              </td>
            </tr>


            <tr onmouseout="refnerf_stop()" onmouseover="refnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <img src='images/ds.png' width="160">
                </div>
              </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <papertitle>Deep Learning, Data Science and Analytics</papertitle>
                  <br>
                  <strong>Aaron Hao Tan</strong>, 2018-2019 &nbsp
                  <br>
                  <a href="https://github.com/aarontan-git/salary_classification">Salary Classification</a>
                  /
                  <a href="https://github.com/aarontan-git/sentiment_analysis">Sentiment Analysis</a>
                  <br>
                  <a href="https://github.com/aarontan-git/news_Busters">Fake News Classification</a>: <a href="files/Fake-News-Detection-Final.pdf">Report</a> / <a href="files/Fake-News-Detector-Slide.pdf">Slide</a>
                  <br>
                  <a href="files/LSTM_mini_lecture.pdf">LSTM Mini Lecture</a>
                  <br>
                  <a href="files/Deep Learning Mini Lecture CLASS.pdf">Deep Learning Mini Lecture</a>


                  <p></p>
                  <p>Completed several projects pertaining to deep learning, data science and analytics.</p>
                </td>
              </tr>

                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one">
                      <div class="two" id='eight_image'><video  width=100% height=100% muted autoplay loop>
                      <source src="images/ebike.mov" type="video/mp4">
                      Your browser does not support the video tag.
                      </video></div>
                      <!-- <img src='images/8x8_static.png' width="160"> -->
                    </div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                      <papertitle>Rider sweat prediction for pedal-assist mode</papertitle>
                      <br>
                      <strong>Aaron Hao Tan</strong>, 2017 &nbsp
                      <br>
                      <a href="https://www.youtube.com/watch?v=WCD9Q_Y4WIA&ab_channel=PedelecsundE-Bikes">ARIV E-Bike</a>
                      <p></p>
                      <p>Internship project at <a href="https://www.gm.ca/en/home.html"> General Motors </a> on a pedal-assisted power mode based on rider sweat onset prediction using machine learning, to enable rider to arrive without breaking a sweat.</p>
                  </td>
                </tr>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Awards</heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>2022</strong>: <a href="https://www.utoronto.ca/news/u-t-sets-stage-strategic-research-partnership-world-s-largest-ride-hailing-company">DiDi Graduate Scholarship ($10k)</a> <br>
            <strong>2022</strong>: <a href="https://www.cos-sco.ca/cos-membership/awards/cos-awards-for-excellence-recipients/">COS: Awards of Excellence in Ophthalmic Research (Finalist)</a><br>
            <strong>2021</strong>: <a href="https://sites.google.com/view/ro-man-2021-r2d2/competition-results?authuser=0">RO-MAN: The Roboethics Competition - 1st Place ($1k)</a> <br>
            <strong>2021</strong>: Best Ophthalmology and Vision Sciences Research Day Paper - University of Toronto <br>
            <strong>2020</strong>: COVID-19 ... <br>
            <strong>2019</strong>: Outstanding Thesis Award - Ontario Tech University (MASc) <br>
            <strong>2018</strong>: <a href="images/feas_grad.png" alt="Image description" target="_blank"> FEAS Graduate Scholarship - Ontario Tech University ($5k)</a> <br>
            <strong>2017</strong>: <a href="images/first_place.jpg" alt="Image description" target="_blank"> 1st Place Senior Engineering Design Competition</a> <br>
            <strong>2017</strong>: Team GM Recognition Award <br>
            <strong>2016</strong>: <a href="images/gm_assembly_plant.png" alt="Image description" target="_blank"> General Motors Assembly Plant Award ($2.5k)</a> <br>
            <strong>2016</strong>: <a href="https://research.ontariotechu.ca/students/nserc-usra.php">NSERC Undergraduate Student Research Awards ($8.6k)</a> <br>
          </td>
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <heading>Teachings</heading>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <td style="padding:20px;width:75%;vertical-align:middle">
            <strong>2022 W</strong>: MIE443: Mechatronics Systems: Design & Integration Tutorial TA <br>
            <strong>2022 W</strong>: ENH610: Parasitology and Pest Control Lab TA <br>
            <strong>2021 W</strong>: MIE443: Mechatronics Systems: Design & Integration Tutorial TA <br>
            <strong>2020 W</strong>: MIE443: Mechatronics Systems: Design & Integration Lab TA <br>
            <strong>2019 W</strong>: MECE3390U: Mechatronics Head TA <br>
            <strong>2018 F</strong>: MECE2230U: Statics Head TA<br>
            <strong>2018 W</strong>: MECE3390U: Mechatronics Head TA <a href="files/MECE3390U-2018W.PDF">(Course Evaluation)</a> <br>
            <strong>2017 F</strong>: MECE3350U Control Systems Head TA <a href="files/MECE3350U-2017F.pdf">(Course Evaluation)</a> <br>
          </td>



        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://github.com/jonbarron/jonbarron_website">source code</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
